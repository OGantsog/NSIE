{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61c7090a-abc6-4e7e-8eea-d5d868ce9e08",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b65e1f07-1c2c-444d-8eee-29edaaa5eb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import mne\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "from preprocessing import preprocess_record, preprocess_all\n",
    "from features import extract_features_all_epochs\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c0290007-5612-4a1e-a7c6-2b83c233f1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SleepStageCNN(nn.Module):\n",
    "    def __init__(self, input_length, n_channels=1, n_classes=5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(\n",
    "            in_channels=n_channels,\n",
    "            out_channels=32,\n",
    "            kernel_size=7,\n",
    "            padding=3\n",
    "        )\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(\n",
    "            in_channels=32,\n",
    "            out_channels=64,\n",
    "            kernel_size=5,\n",
    "            padding=2\n",
    "        )\n",
    "\n",
    "        # Global average pooling will reduce temporal dimension\n",
    "        self.gap = nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "        self.fc = nn.Linear(64, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, channels, samples)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.gap(x)          # → (batch, 64, 1)\n",
    "        x = x.squeeze(-1)        # → (batch, 64)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a540a803-f797-472e-8142-608251300284",
   "metadata": {},
   "source": [
    "### Instantiate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd070281-404c-4b32-b423-9c87e6a701ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SleepStageCNN(\n",
       "  (conv1): Conv1d(1, 32, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "  (pool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv1d(32, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "  (gap): AdaptiveAvgPool1d(output_size=1)\n",
       "  (fc): Linear(in_features=64, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_length = 3000  # example for 30s @ 100Hz\n",
    "model = SleepStageCNN(input_length=input_length, n_channels=1, n_classes=5)\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd78228a-95e6-46ae-a438-34e357b510fa",
   "metadata": {},
   "source": [
    "### Optimizer, Loss, LR Schedule and Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5a78050a-b785-4950-95d8-215c373504ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=1e-6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "110fbffd-095b-4b6e-ab28-8a0070acfd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#early stopping helper\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "        self.should_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif val_loss > self.best_loss - self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.should_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ae2461-7b86-4a03-b751-03bb7a499a2d",
   "metadata": {},
   "source": [
    "### Data reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2b7c23b4-64bc-49fe-81d2-818358f98e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sleep_edf(psg_file, hyp_file, channel=\"EEG Fpz-Cz\", epoch_length=30):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        X: np array (n_epochs, samples)\n",
    "        y: np array (n_epochs,)\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Load PSG ---\n",
    "    raw = mne.io.read_raw_edf(psg_file, preload=True)\n",
    "    raw.pick_channels([channel])\n",
    "    raw.filter(0.3, 35)\n",
    "    ann = mne.read_annotations(hyp_file)\n",
    "    raw.set_annotations(ann, emit_warning=False)\n",
    "\n",
    "    # Map annotation labels → integers\n",
    "    # You may customize this mapping\n",
    "    stage_map = {\n",
    "        \"Sleep stage W\": 0,\n",
    "        \"Sleep stage 1\": 1,\n",
    "        \"Sleep stage 2\": 2,\n",
    "        \"Sleep stage ?\": 2,\n",
    "        \"Sleep stage 3\": 3,\n",
    "        \"Sleep stage 4\": 3,# or 3/4 combined\n",
    "        \"Sleep stage R\": 4,\n",
    "    }\n",
    "\n",
    "    # Create events from annotations\n",
    "    events, event_ids = mne.events_from_annotations(raw, chunk_duration=epoch_length)\n",
    "\n",
    "    # Epoch the PSG data\n",
    "    epochs = mne.Epochs(raw, events, event_ids, tmin=0, tmax=epoch_length, baseline=None, preload=True)\n",
    "\n",
    "    # Convert to (n_epochs, samples)\n",
    "    X = epochs.get_data().squeeze(1)  # remove channel dimension if only one channel\n",
    "\n",
    "    # Convert event IDs to labels\n",
    "    y = np.array([stage_map.get(k, -1) for k in epochs.events[:, 2]])\n",
    "\n",
    "    # Remove undefined stages (movement, unknown)\n",
    "    mask = y != -1\n",
    "    X = X[mask]\n",
    "    y = y[mask]\n",
    "\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4f7186d4-02e3-4c7c-96b6-1df5a6da80c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found pairs: 5\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "RAW_DIR = Path(\"sample_data\")\n",
    "\n",
    "def get_record_pairs(raw_dir):\n",
    "    \"\"\"Return list of (psg_file, hyp_file) pairs.\"\"\"\n",
    "    psg_files = {}\n",
    "    hyp_files = {}\n",
    "\n",
    "    for f in raw_dir.glob(\"*.edf\"):\n",
    "        name = f.name\n",
    "        if \"-PSG\" in name:\n",
    "            key = name.split(\"-\")[0]   # e.g., \"SC4001E0\"\n",
    "            psg_files[key] = f\n",
    "        if \"Hypnogram\" in name:\n",
    "            key = name.split(\"-\")[0]   # e.g., \"SC4001EC\"\n",
    "            # Normalize key to match PSG key\n",
    "            key = key.replace(\"EC\", \"E0\").replace(\"EH\", \"E0\")\n",
    "            hyp_files[key] = f\n",
    "\n",
    "    pairs = []\n",
    "    for key in psg_files:\n",
    "        if key in hyp_files:\n",
    "            pairs.append((psg_files[key], hyp_files[key]))\n",
    "        else:\n",
    "            print(f\"⚠️ Missing hypnogram for {key}\")\n",
    "\n",
    "    return pairs\n",
    "\n",
    "pairs = get_record_pairs(RAW_DIR)\n",
    "print(\"Found pairs:\", len(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7f23cfc9-4513-46cc-821c-42d86f34f557",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing SC4002E0-PSG.edf\n",
      "Extracting EDF parameters from /Users/onogantsog/Code/stageclassification/sample_data/SC4002E0-PSG.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 8489999  =      0.000 ... 84899.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/onogantsog/Code/stageclassification/preprocessing.py:53: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
      "  raw = mne.io.read_raw_edf(psg_path, preload=True)\n",
      "/Users/onogantsog/Code/stageclassification/preprocessing.py:53: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
      "  raw = mne.io.read_raw_edf(psg_path, preload=True)\n",
      "/Users/onogantsog/Code/stageclassification/preprocessing.py:53: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
      "  raw = mne.io.read_raw_edf(psg_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/onogantsog/Code/stageclassification/preprocessing.py:55: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw.set_annotations(ann)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing SC4011E0-PSG.edf\n",
      "Extracting EDF parameters from /Users/onogantsog/Code/stageclassification/sample_data/SC4011E0-PSG.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 8405999  =      0.000 ... 84059.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/onogantsog/Code/stageclassification/preprocessing.py:53: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
      "  raw = mne.io.read_raw_edf(psg_path, preload=True)\n",
      "/Users/onogantsog/Code/stageclassification/preprocessing.py:53: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
      "  raw = mne.io.read_raw_edf(psg_path, preload=True)\n",
      "/Users/onogantsog/Code/stageclassification/preprocessing.py:53: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
      "  raw = mne.io.read_raw_edf(psg_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/onogantsog/Code/stageclassification/preprocessing.py:55: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw.set_annotations(ann)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing SC4021E0-PSG.edf\n",
      "Extracting EDF parameters from /Users/onogantsog/Code/stageclassification/sample_data/SC4021E0-PSG.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 8411999  =      0.000 ... 84119.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/onogantsog/Code/stageclassification/preprocessing.py:53: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
      "  raw = mne.io.read_raw_edf(psg_path, preload=True)\n",
      "/Users/onogantsog/Code/stageclassification/preprocessing.py:53: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
      "  raw = mne.io.read_raw_edf(psg_path, preload=True)\n",
      "/Users/onogantsog/Code/stageclassification/preprocessing.py:53: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
      "  raw = mne.io.read_raw_edf(psg_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/onogantsog/Code/stageclassification/preprocessing.py:55: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw.set_annotations(ann)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing SC4012E0-PSG.edf\n",
      "Extracting EDF parameters from /Users/onogantsog/Code/stageclassification/sample_data/SC4012E0-PSG.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 8549999  =      0.000 ... 85499.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/onogantsog/Code/stageclassification/preprocessing.py:53: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
      "  raw = mne.io.read_raw_edf(psg_path, preload=True)\n",
      "/Users/onogantsog/Code/stageclassification/preprocessing.py:53: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
      "  raw = mne.io.read_raw_edf(psg_path, preload=True)\n",
      "/Users/onogantsog/Code/stageclassification/preprocessing.py:53: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
      "  raw = mne.io.read_raw_edf(psg_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/onogantsog/Code/stageclassification/preprocessing.py:55: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw.set_annotations(ann)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing SC4001E0-PSG.edf\n",
      "Extracting EDF parameters from /Users/onogantsog/Code/stageclassification/sample_data/SC4001E0-PSG.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 7949999  =      0.000 ... 79499.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/onogantsog/Code/stageclassification/preprocessing.py:53: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
      "  raw = mne.io.read_raw_edf(psg_path, preload=True)\n",
      "/Users/onogantsog/Code/stageclassification/preprocessing.py:53: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
      "  raw = mne.io.read_raw_edf(psg_path, preload=True)\n",
      "/Users/onogantsog/Code/stageclassification/preprocessing.py:53: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
      "  raw = mne.io.read_raw_edf(psg_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/onogantsog/Code/stageclassification/preprocessing.py:55: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw.set_annotations(ann)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "X_all, y_all = [], []\n",
    "\n",
    "for (psg, hyp) in pairs:\n",
    "    psg_path = str(psg)\n",
    "    hyp_path = str(hyp)\n",
    "\n",
    "    print(f\"Processing {os.path.basename(psg)}\")\n",
    "    X, y = preprocess_record(psg_path, hyp_path)\n",
    "    X_all.append(X)\n",
    "    y_all.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "808a3246-68d0-48cf-b40f-76275e6d72fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all2 = np.concatenate(X_all, axis=0)\n",
    "y_all2 = np.concatenate(y_all, axis=0)\n",
    "df_xall = pd.DataFrame(X_all2)\n",
    "df_yall = pd.DataFrame(y_all2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d3105d9f-3d27-4c5f-99bd-6a56c5489f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_all2, y_all2, test_size=0.2, random_state=42, stratify=y_all2\n",
    ")\n",
    "\n",
    "X_train = X_train[:, np.newaxis, :]  # add channel dim\n",
    "X_val   = X_val[:, np.newaxis, :]\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val = torch.tensor(y_val, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237cbfd8-59da-4b1a-9972-db314c40c2f2",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f6ede42c-a7a7-4312-8a95-70fcc80e6f37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Val Loss: 1.0075\n",
      "Epoch 2/100, Val Loss: 1.0073\n",
      "Epoch 3/100, Val Loss: 1.0084\n",
      "Epoch 4/100, Val Loss: 1.0123\n",
      "Epoch 5/100, Val Loss: 1.0145\n",
      "Epoch 6/100, Val Loss: 1.0099\n",
      "Epoch 7/100, Val Loss: 1.0072\n",
      "Epoch 8/100, Val Loss: 1.0083\n",
      "Epoch 9/100, Val Loss: 1.0072\n",
      "Epoch 10/100, Val Loss: 1.0084\n",
      "Epoch 11/100, Val Loss: 1.0079\n",
      "Epoch 12/100, Val Loss: 1.0074\n",
      "Epoch 13/100, Val Loss: 1.0078\n",
      "Epoch 14/100, Val Loss: 1.0076\n",
      "Epoch 15/100, Val Loss: 1.0071\n",
      "Epoch 16/100, Val Loss: 1.0072\n",
      "Epoch 17/100, Val Loss: 1.0069\n",
      "Epoch 18/100, Val Loss: 1.0071\n",
      "Epoch 19/100, Val Loss: 1.0072\n",
      "Epoch 20/100, Val Loss: 1.0075\n",
      "Epoch 21/100, Val Loss: 1.0074\n",
      "Epoch 22/100, Val Loss: 1.0076\n",
      "Epoch 23/100, Val Loss: 1.0089\n",
      "Epoch 24/100, Val Loss: 1.0072\n",
      "Epoch 25/100, Val Loss: 1.0070\n",
      "Epoch 26/100, Val Loss: 1.0070\n",
      "Epoch 27/100, Val Loss: 1.0072\n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(TensorDataset(X_val, y_val), batch_size=batch_size)\n",
    "\n",
    "early_stopping = EarlyStopping(patience=10)\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for X, y in train_loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X)\n",
    "        loss = criterion(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in val_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            preds = model(X)\n",
    "            loss = criterion(preds, y)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "\n",
    "    lr_scheduler.step(val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    early_stopping(val_loss)\n",
    "    if early_stopping.should_stop:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8e36cb52-6829-44c8-9caa-86a3db4b3bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found pairs: 1\n"
     ]
    }
   ],
   "source": [
    "TEST_DIR = Path(\"testing_data\")\n",
    "pairs = get_record_pairs(TEST_DIR)\n",
    "print(\"Found pairs:\", len(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cf3b1de7-6929-41b9-a448-24d4d45ce2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing SC4061E0-PSG.edf\n",
      "Extracting EDF parameters from /Users/onogantsog/Code/stageclassification/testing_data/SC4061E0-PSG.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 8309999  =      0.000 ... 83099.990 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/onogantsog/Code/stageclassification/preprocessing.py:53: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
      "  raw = mne.io.read_raw_edf(psg_path, preload=True)\n",
      "/Users/onogantsog/Code/stageclassification/preprocessing.py:53: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
      "  raw = mne.io.read_raw_edf(psg_path, preload=True)\n",
      "/Users/onogantsog/Code/stageclassification/preprocessing.py:53: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
      "  raw = mne.io.read_raw_edf(psg_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/onogantsog/Code/stageclassification/preprocessing.py:55: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw.set_annotations(ann)\n"
     ]
    }
   ],
   "source": [
    "X_test_list = []\n",
    "y_test_list = []\n",
    "\n",
    "for (psg, hyp) in pairs:\n",
    "    psg_path = str(psg)\n",
    "    hyp_path = str(hyp)\n",
    "\n",
    "    print(f\"Processing {os.path.basename(psg)}\")\n",
    "    test_X, test_y = preprocess_record(psg_path, hyp_path)\n",
    "\n",
    "    X_test_list.append(test_X)\n",
    "    y_test_list.append(test_y)\n",
    "\n",
    "# Concatenate epochs\n",
    "X_test = np.concatenate(X_test_list, axis=0)  # (N, 3000)\n",
    "y_test = np.concatenate(y_test_list, axis=0)  # (N,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a3aa104e-177f-465a-810c-20ca7db4f817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique epoch lengths: {3000}\n"
     ]
    }
   ],
   "source": [
    "# Add channel dimension\n",
    "X_test = X_test[:, None, :]   # (N, 1, 3000)\n",
    "\n",
    "# Convert to torch\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long).to(device)\n",
    "lengths = {x.shape[1] for x in X_test_list}\n",
    "print(\"Unique epoch lengths:\", lengths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bcf904-b356-4230-a435-86460031a5aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e97832-de6e-49ba-a69b-344a975f1db4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25145150-34c0-40c1-b91a-fb420f4985b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5071e6d0-6e82-465c-9774-40228b5a3947",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9f4e88ec-62c4-4add-a569-9cc6bd19a0cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 2770 at dim 0 (got 3000)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_test \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(X_test, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      2\u001b[0m y_test \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(y_test, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mValueError\u001b[0m: expected sequence of length 2770 at dim 0 (got 3000)"
     ]
    }
   ],
   "source": [
    "X_test = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7a9cc937-7f06-4464-833c-98aebd60ea27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SleepStageCNN(\n",
       "  (conv1): Conv1d(1, 32, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "  (pool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv1d(32, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "  (gap): AdaptiveAvgPool1d(output_size=1)\n",
       "  (fc): Linear(in_features=64, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "042eca11-a84f-4faa-86b4-4d58460f72e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test)\n",
    "    preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "    y_true = y_test.cpu().numpy()\n",
    "    y_pred = preds.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a194de9e-c2e8-46d0-94b9-779ca80393bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7469314079422382\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           W       0.75      1.00      0.86      2069\n",
      "          N1       0.00      0.00      0.00        56\n",
      "          N2       0.00      0.00      0.00       407\n",
      "          N3       0.00      0.00      0.00       136\n",
      "         REM       0.00      0.00      0.00       102\n",
      "\n",
      "    accuracy                           0.75      2770\n",
      "   macro avg       0.15      0.20      0.17      2770\n",
      "weighted avg       0.56      0.75      0.64      2770\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "print(classification_report(\n",
    "    y_true, y_pred,\n",
    "    target_names=[\"W\", \"N1\", \"N2\", \"N3\", \"REM\"]\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ae907a42-b903-4ccb-8ddc-7cb9d6f14576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2069    0    0    0    0]\n",
      " [  56    0    0    0    0]\n",
      " [ 407    0    0    0    0]\n",
      " [ 136    0    0    0    0]\n",
      " [ 102    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd4a501-4e0a-455a-a9f7-d6f5f168c2e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
